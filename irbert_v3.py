# -*- coding: utf-8 -*-
"""IRBERT_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsr2bBYT8hfUtkF7BmOBu2OpTs5MpNoh
"""

!pip install transformers

import os
from pathlib import Path
from transformers import BertTokenizer, BertModel
import torch
from torch.utils.data import DataLoader, TensorDataset

# Check if a GPU is available and use it, otherwise, use the CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

ir_path = "/content/drive/MyDrive/Research /Clemson/Thomas_Clemson_IR/syr2k_recreations"
text_irs = "./text_irs"

#os.mkdir(ir_path)
os.mkdir(text_irs)

def convert_ll_to_txt(ll_filename, output_directory):
    # Read the content of the .ll file
    with open(ll_filename, 'r') as ll_file:
        ll_content = ll_file.read()

    # Create the corresponding .txt filename in the output directory
    txt_filename = os.path.join(output_directory, os.path.basename(ll_filename).replace('.ll', '.txt'))

    # Write the content to the .txt file
    with open(txt_filename, 'w') as txt_file:
        txt_file.write(ll_content)

    print(f"Conversion successful: {os.path.basename(ll_filename)} -> {os.path.basename(txt_filename)}")

def convert_all_ll_to_txt(directory_path, output_directory):
    # Get a list of all files in the specified directory
    all_files = os.listdir(directory_path)

    # Filter out only the .ll files
    ll_files = [file for file in all_files if file.endswith('.ll')]

    # Ensure the output directory exists, create it if necessary
    os.makedirs(output_directory, exist_ok=True)

    # Iterate over the .ll files and convert each one to .txt
    for ll_file in ll_files:
        ll_file_path = os.path.join(directory_path, ll_file)
        convert_ll_to_txt(ll_file_path, output_directory)

# Specify the directory containing the .ll files
input_directory = ir_path

# Specify the output directory for the .txt files
output_directory = text_irs

# Call the function to convert all .ll files to .txt and save them in the ll_txt directory
convert_all_ll_to_txt(input_directory, output_directory)

data_dir = text_irs
text_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]

data = []
for file_name in text_files:
    with open(os.path.join(data_dir, file_name), 'r') as file:
        text = file.read()
        data.append(text)

print(len(data))

# Step 4: Define and train the BERT model
model = BertModel.from_pretrained('bert-base-uncased').to(device)

# Step 2: Tokenize and convert the text data to tensors
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize and encode the text data
encoded_data = tokenizer(data, padding=True, truncation=True, return_tensors='pt')

# Step 3: Create DataLoader for batching
dataset = TensorDataset(encoded_data['input_ids'], encoded_data['attention_mask'])
dataloader = DataLoader(dataset, batch_size=8, shuffle=True)



for input_ids, attention_mask in dataloader:
    input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)
    outputs = model(input_ids, attention_mask=attention_mask)



print(outputs)

# Step 5: Save the model embeddings
torch.save(model.state_dict(), 'bert_model_embeddings.pth')

# Step 6: Load the saved model embeddings
loaded_model = BertModel.from_pretrained('bert-base-uncased')
loaded_model.load_state_dict(torch.load('bert_model_embeddings.pth'))
loaded_model.to(device)

print(model)

# Step 8: Generate embeddings for new text input
def generate_embeddings(text):
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)

    with torch.no_grad():
        outputs = loaded_model(**inputs)

    # Extract embeddings from the last hidden state
    embeddings = outputs.last_hidden_state[:, 0, :]

    return embeddings

test_ir_path = "./test_text_irs"

os.mkdir(test_ir_path)

# Specify the directory containing the .ll files
test_input_directory = "/content/drive/MyDrive/Research /Clemson/Thomas_Clemson_IR/syr2k_exhaustive"

# Specify the output directory for the .txt files
output_directory = test_ir_path

# Call the function to convert all .ll files to .txt and save them in the ll_txt directory
convert_all_ll_to_txt(test_input_directory, output_directory)

embedding_path = "./embeddings"

#!rm -rf 'test_text_irs'

os.mkdir(embedding_path)

data_dir = test_ir_path
test_text_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]

test_data = []
for file_name in test_text_files:
    with open(os.path.join(data_dir, file_name), 'r') as file:
        text = file.read()
        # Create the corresponding .txt filename in the output directory
        emb_filename = os.path.join(embedding_path, os.path.basename(file_name).replace('.txt', ''))
        embeddings = generate_embeddings(text)
        torch.save(embeddings, f'{emb_filename}.pth')
        # print(embeddings)

print(len(test_text_files))



print("Generated Embeddings Shape:", embeddings)



!zip -r embeddings.zip embeddings/